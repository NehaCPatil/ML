{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Large Movie Review Dataset\n",
    "\n",
    "We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. \n",
    "There is additional unlabeled data for use as well. \n",
    "Raw text and already processed bag of words formats are provided\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "from nltk.corpus import movie_reviews\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, in plain English, the above code is translated to: \n",
    "In each category (we have pos or neg), take all of the file IDs (each review has its own ID), \n",
    "then store the word_tokenized version (a list of words) for the file ID, followed by the positive or negative \n",
    "label in one big list.\n",
    "\n",
    "Next, we use random to shuffle our documents. \n",
    "This is because we're going to be training and testing. If we left them in order, chances are we'd train on \n",
    "all of the negatives, some positives, and then test only against positives. \n",
    "We don't want that, so we shuffle the data.\n",
    "\n",
    "Then, just so you can see the data you are working with, we print out documents[1], \n",
    "which is a big list, where the first element is a list the words, and \n",
    "the 2nd element is the \"pos\" or \"neg\" label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "# def find_features(documents):\n",
    "#     words = tuple(documents)\n",
    "#     features = {}\n",
    "#     for w in word_features:\n",
    "#         features[w] = (w in words)\n",
    "\n",
    "#     return features\n",
    "\n",
    "# features = find_features(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting words to Features with NLTK\n",
    "\n",
    "Mostly the same as before, only with now a new variable, word_features, which contains the top 3,000 \n",
    "most common words. Next, we're going to build a quick function that will find these top 3,000 words in \n",
    "our positive and negative documents, marking their presence as either positive or negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(documents):\n",
    "    words = tuple(documents)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "features = find_features(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we can print one feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can do this for all of our documents, saving the feature existence booleans and their \n",
    "respective positive or negative categories by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to go ahead and split up the data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set that we'll train our classifier with\n",
    "training_set = featuresets[:1900]\n",
    "\n",
    "# set that we'll cross validation our classifier with\n",
    "cross_validation=training_set[:400]\n",
    "\n",
    "# set that we'll test against.\n",
    "testing_set = featuresets[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file, where you want to store the data\n",
    "file = open('testing.pickel', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(testing_set, file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier with NLTK:\n",
    "    This is a pretty popular algorithm used in text classification, so it is only fitting that we try it \n",
    "    out first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy percent training_set: 87.25\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier accuracy percent training_set:\",(nltk.classify.accuracy(classifier, cross_validation))*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   sucks = True              neg : pos    =     17.6 : 1.0\n",
      "                  annual = True              pos : neg    =      9.7 : 1.0\n",
      "                     ugh = True              neg : pos    =      9.6 : 1.0\n",
      "                 frances = True              pos : neg    =      9.1 : 1.0\n",
      "                   groan = True              neg : pos    =      7.6 : 1.0\n",
      "              schumacher = True              neg : pos    =      7.4 : 1.0\n",
      "             silverstone = True              neg : pos    =      7.0 : 1.0\n",
      "                 idiotic = True              neg : pos    =      7.0 : 1.0\n",
      "                  shoddy = True              neg : pos    =      7.0 : 1.0\n",
      "           unimaginative = True              neg : pos    =      7.0 : 1.0\n",
      "               atrocious = True              neg : pos    =      6.6 : 1.0\n",
      "                obstacle = True              pos : neg    =      6.4 : 1.0\n",
      "                 cunning = True              pos : neg    =      6.4 : 1.0\n",
      "               pregnancy = True              neg : pos    =      6.3 : 1.0\n",
      "                  turkey = True              neg : pos    =      6.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Classifiers with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_classifier = open(\"naivebayes.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
