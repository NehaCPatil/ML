{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class SimpleLR:\n",
    "    \n",
    "    #class constructor\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 0.001\n",
    "        self.epoch = 10000\n",
    "        self.theta_0 = 0.5\n",
    "        self.theta_1 = 0.75\n",
    "        \n",
    "        \n",
    "     # fuction for display csv file\n",
    "    def display_data(self):\n",
    "       \n",
    "       # Exception handling for file \n",
    "        try:\n",
    "           # for user input file name\n",
    "           self.file = input(\"\\n Enter file name:-\")\n",
    "           # read csv file\n",
    "           self.df = pd.read_csv(self.file)\n",
    "\n",
    "           # for user input file name\n",
    "           self.file = input(\"\\n Enter file name:-\")\n",
    "\n",
    "           # read csv file\n",
    "           self.df_1 = pd.read_csv(self.file)\n",
    " \n",
    "       \n",
    "        # if file not found the error\n",
    "        except OSError as e:\n",
    "           # print exception\n",
    "           print(\"File not found\")\n",
    "  \n",
    "\n",
    "    \"\"\"Handling missing data\"\"\"\n",
    "    def handling_missing_data(self):\n",
    "       \n",
    "       # check data type of all variable\n",
    "        print(\"\\n\",self.df.dtypes)\n",
    "       \n",
    "       # check for null value\n",
    "        print(\"\\n\\n\",self.df.isnull().sum())\n",
    "\n",
    "       # replacing missing values with mean\n",
    "\n",
    "        self.df['x'].replace(np.NaN,self.df['x'].mean(), inplace = True)\n",
    "       \n",
    "        self.df['y'].replace(np.NaN,self.df['y'].mean(), inplace = True)\n",
    "       \n",
    "       # check data type of all variable\n",
    "        print(\"\\n\",self.df_1.dtypes,)\n",
    "       \n",
    "       # check for null value\n",
    "        print(\"\\n\\n\",self.df_1.isnull().sum())\n",
    "\n",
    "       # replacing missing values with mean\n",
    "\n",
    "        self.df_1['x'].replace(np.NaN,self.df_1['x'].mean(), inplace = True)\n",
    "        self.df_1['y'].replace(np.NaN,self.df_1['y'].mean(), inplace = True)\n",
    "       \n",
    "       \n",
    "       \n",
    "\n",
    "          \n",
    "    \"\"\"Feature scaling\"\"\"  \n",
    "    def feature_scaling(self):\n",
    "       # Simple feature scaling\n",
    "        self.df[\"x\"] = self.df[\"x\"]/self.df[\"x\"].max()\n",
    "        self.df[\"y\"]= self.df[\"y\"]/self.df[\"y\"].max()\n",
    "        print(\"Simple feature scaling\")\n",
    "\n",
    "    def split(self):\n",
    "        print(\"Convert pandas datafrem into numpy\")\n",
    "        \n",
    "        x_train_data = np.array(self.df.x[:len(self.df.x)])   \n",
    "        y_train_data = np.array(self.df.y[:len(self.df.y)])\n",
    "\n",
    "        x_test_data = np.array(self.df_1.x[:len(self.df_1.x)])\n",
    "        y_test_data = np.array(self.df_1.y[:len(self.df_1.y)])\n",
    "        \n",
    "       \n",
    "        return x_train_data, y_train_data, x_test_data, y_test_data\n",
    "    \n",
    "    def gradient_descent(self,x_train_data, y_train_data):\n",
    "\n",
    "        size = len(x_train_data)\n",
    "        vector = np.ones(size)\n",
    "        hypo_1 = 0.0\n",
    "        hypo_2 = 0.0\n",
    "        cost_temp = 0.0\n",
    "        for i in range(self.epoch):\n",
    "            for row in range(size):\n",
    "\n",
    "                hypo_1 +=((self.theta_0 * vector[row])  + (self.theta_1 * x_train_data[row]))- y_train_data[row]\n",
    "                hypo_2 +=(((self.theta_0 *  vector[row]) + (self.theta_1 * x_train_data[row])) - y_train_data[row]) * x_train_data[row]\n",
    "                \n",
    "\n",
    "            cost_temp +=(((self.theta_0 * vector[row])  + (self.theta_1 * x_train_data[row]))- y_train_data[row]) ** 2 \n",
    "            cost = (1/2 * size)* cost_temp\n",
    "            self.theta_0 = self.theta_0 -((self.learning_rate/ size) * hypo_1)\n",
    "            self.theta_1 = self.theta_1 -((self.learning_rate/ size)* hypo_2)\n",
    "            \n",
    "        return [self.theta_0,self.theta_1], cost\n",
    "    \n",
    "        \n",
    "       \n",
    "    def predict (self, x_test_data,theta_00):\n",
    "        \n",
    "        n = len(x_test_data)\n",
    "        y_predict = [None]*n\n",
    "        vector = np.ones(n)\n",
    "        for row in range (n):\n",
    "            y_predict[row] = theta_00[0] * vector[row]  + theta_00[1] * x_test_data[row] \n",
    "        return y_predict\n",
    "   \n",
    "     \n",
    "    def accuracy(self, y_test_data, y_predict):\n",
    "         \n",
    "        print(\"y\", y_test_data.shape)\n",
    "        total_error = 0\n",
    "        for i in range(0, len(y_test_data)):\n",
    "            total_error += abs((y_predict[i] - y_test_data[i]) / y_test_data[i])\n",
    "        total_error = (total_error / len(y_test_data))\n",
    "        accuracy = 1 - total_error\n",
    "        return accuracy * 100\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "obj = SimpleLR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Show dataset details:----------\n",
      "\n",
      " Enter file name:-train.csv\n",
      "\n",
      " Enter file name:-test.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------Show dataset details:----------\")\n",
    "obj.display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------Handling Missing Data:----------\n",
      "\n",
      " x    float64\n",
      "y    float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      " x    0\n",
      "y    1\n",
      "dtype: int64\n",
      "\n",
      " x      int64\n",
      "y    float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      " x    0\n",
      "y    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------Handling Missing Data:----------\")\n",
    "obj.handling_missing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple feature scaling\n"
     ]
    }
   ],
   "source": [
    "obj.feature_scaling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas datafrem into numpy\n"
     ]
    }
   ],
   "source": [
    "x_train_data, y_train_data, x_test_data, y_test_data = obj.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_0 , cost = obj.gradient_descent(x_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = obj.predict (x_test_data,theta_0)\n",
    "# print(\"Prediction\", y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y (300,)\n",
      "Accuracy 77.4370554191209\n"
     ]
    }
   ],
   "source": [
    "acc = obj.accuracy(y_test_data, y_predict)\n",
    "print(\"Accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
