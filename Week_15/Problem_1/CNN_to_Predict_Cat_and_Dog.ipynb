{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "    Apply CNN to predict cat and dog from given image dataset\n",
    "    \n",
    "    \n",
    "Layers needed by CNN\n",
    "\n",
    "Conv2D :- Basic Convolutional layer . Here we will be using a 64 neuron layer\n",
    "\n",
    "Dense :- Dense layer is needed by every neural network to finally output the result however every once in while using a Dense layer helps in making model learn.\n",
    "\n",
    "MaxPooling :- CNN has a concept of max pooling. After every convoulution we get some values in a kernel. However in max pooling we select max kernel value.\n",
    "\n",
    "Flatten:- Conv2D layer returns doesn't return a flatten data hence we need Flatten layer before feeding it into final Dense layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enough of data processing I wanna train :) Here are the steps to do define our CNN model\n",
    "\n",
    "Define a Sequential model\n",
    "Start adding layers to it.\n",
    "First we will add a Conv2D layer with 64 nodes and kernel size of (3,3). \n",
    "You can also experiment with different values here like 32, 128 etc. \n",
    "Also we have to specify input shape which is your X shape. \n",
    "Activation we will take 'relu' for now however there are many others to experiment with.\n",
    "\n",
    "Now after every Conv layer we always do max pooling so we will add max pooling layer \n",
    "with a size of (2,2)\n",
    "\n",
    "We will repeat this combination again because come on 2 is better than one. Haha.\n",
    "We you can also add 3 or more convolution layers but keep in mind the more layers you add more time it will take to train.\n",
    "But we don't have much time so we will add a flatten layer now. As we have to feed our data to Dense layer later.\n",
    "\n",
    "We will now add a Dense layer of 64 nodes. Note for all these layers we are using activation as 'relu' because I found results better with this.\n",
    "You can skip specifying activation but this might make a model a conveniently linear which might not work for us.\n",
    "In the end for getting our result we will add final Dense layer . \n",
    "Activation can be sigmoid or softmax (if you need probability use sigmoid else use softmax). \n",
    "Here I have used sigmoid.\n",
    "\n",
    "Finally we will compile the model . \n",
    "There are 3 things to mention here . Loss, Optimizer, Metrics\n",
    "\n",
    "Loss :- To make our model better we either minimize loss or maximize accuracy. \n",
    "NN always minimize loss. To measure it we can use different formulas like 'categorical_crossentropy' or 'binary_crossentropy'. Here I have used binary_crossentropy\n",
    "\n",
    "Optimizer :- If you know a lil bit about mathematics of machine learning you might \n",
    "be familier with local minima or global minima or cost function. \n",
    "To minimize cost function we use different methods For ex :- like gradient descent, stochastic gradient descent. So these are call optimizers. We are using a default one here which is adam\n",
    "\n",
    "Metrics :- This is to denote the measure of your model. \n",
    "    Can be accuracy or some other metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras # Test out Theano when time permits as well\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,MaxPooling2D,Convolution2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the ANN\n",
    "\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/admin1/anaconda3/envs/newenvt/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/newenvt/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 3...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# step1 - Convolution layer\n",
    "\n",
    "classifier.add(Convolution2D(32,3,3, input_shape =(64,64,3),activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 - Pooling layer\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/newenvt/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(32,3,3,activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s time for us to now convert all the pooled images into a continuous vector through Flattening.\n",
    "Flattening is a very important step to understand. \n",
    "What we are basically doing here is taking the 2-D array, \n",
    "i.e pooled image pixels and converting them to a one dimensional single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 - Flattening\n",
    "\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we need to create a fully connected layer, \n",
    "and to this layer we are going to connect the set of nodes we got after the flattening step,\n",
    "these nodes will act as an input layer to these fully-connected layers.\n",
    "As this layer will be present between the input layer and output layer, \n",
    "we can refer to it a hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/anaconda3/envs/newenvt/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=300, activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/admin1/anaconda3/envs/newenvt/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# step 4 - Full connection\n",
    "\n",
    "classifier.add(Dense(output_dim = 300, activation='relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step - 5 Compiling the CNN\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator class from Keras.\n",
    "\n",
    "CNN model is ready to rumble. Further we use ImageDataGenerator class from Keras. \n",
    "It’s generate batches of image(matrix) data with real-time data augmentation(image processing). \n",
    "The data will be looped over (in batches) indefinitely\n",
    "\n",
    "\n",
    "\n",
    "Now we will fit our model with training data.\n",
    "\n",
    "Epochs :- How many times our model will go through data\n",
    "\n",
    "Batch size :- How much amount of data at once you wanna pass through the model\n",
    "\n",
    "validation_split :- How much amount of data (in this case its 20 %) you will need to check cross validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8001 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From /home/admin1/anaconda3/envs/newenvt/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/25\n",
      "80/80 [==============================] - 43s 536ms/step - loss: 0.6955 - acc: 0.5258 - val_loss: 0.6887 - val_acc: 0.5734\n",
      "Epoch 2/25\n",
      "80/80 [==============================] - 36s 449ms/step - loss: 0.6770 - acc: 0.5773 - val_loss: 0.6525 - val_acc: 0.6484\n",
      "Epoch 3/25\n",
      "80/80 [==============================] - 36s 447ms/step - loss: 0.6635 - acc: 0.6164 - val_loss: 0.6728 - val_acc: 0.5750\n",
      "Epoch 4/25\n",
      "80/80 [==============================] - 13s 167ms/step - loss: 0.6564 - acc: 0.6161 - val_loss: 0.6798 - val_acc: 0.5929\n",
      "Epoch 5/25\n",
      "80/80 [==============================] - 13s 161ms/step - loss: 0.6405 - acc: 0.6371 - val_loss: 0.6171 - val_acc: 0.6922\n",
      "Epoch 6/25\n",
      "80/80 [==============================] - 13s 160ms/step - loss: 0.6189 - acc: 0.6637 - val_loss: 0.6061 - val_acc: 0.6719\n",
      "Epoch 7/25\n",
      "80/80 [==============================] - 13s 157ms/step - loss: 0.6212 - acc: 0.6585 - val_loss: 0.6395 - val_acc: 0.6458\n",
      "Epoch 8/25\n",
      "80/80 [==============================] - 13s 160ms/step - loss: 0.6103 - acc: 0.6723 - val_loss: 0.5868 - val_acc: 0.6937\n",
      "Epoch 9/25\n",
      "80/80 [==============================] - 13s 162ms/step - loss: 0.5898 - acc: 0.6875 - val_loss: 0.6001 - val_acc: 0.6906\n",
      "Epoch 10/25\n",
      "80/80 [==============================] - 14s 177ms/step - loss: 0.5933 - acc: 0.6785 - val_loss: 0.5843 - val_acc: 0.7308\n",
      "Epoch 11/25\n",
      "80/80 [==============================] - 14s 173ms/step - loss: 0.5808 - acc: 0.6937 - val_loss: 0.5561 - val_acc: 0.7344\n",
      "Epoch 12/25\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.5743 - acc: 0.7062 - val_loss: 0.5604 - val_acc: 0.7312\n",
      "Epoch 13/25\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.5642 - acc: 0.7110 - val_loss: 0.6260 - val_acc: 0.6747\n",
      "Epoch 14/25\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.5550 - acc: 0.7195 - val_loss: 0.5263 - val_acc: 0.7375\n",
      "Epoch 15/25\n",
      "80/80 [==============================] - 13s 167ms/step - loss: 0.5391 - acc: 0.7379 - val_loss: 0.5650 - val_acc: 0.7063\n",
      "Epoch 16/25\n",
      "80/80 [==============================] - 13s 163ms/step - loss: 0.5380 - acc: 0.7211 - val_loss: 0.5440 - val_acc: 0.7244\n",
      "Epoch 17/25\n",
      "80/80 [==============================] - 13s 163ms/step - loss: 0.5173 - acc: 0.7480 - val_loss: 0.5000 - val_acc: 0.7562\n",
      "Epoch 18/25\n",
      "80/80 [==============================] - 14s 172ms/step - loss: 0.5296 - acc: 0.7273 - val_loss: 0.5398 - val_acc: 0.7406\n",
      "Epoch 19/25\n",
      "80/80 [==============================] - 13s 161ms/step - loss: 0.4999 - acc: 0.7582 - val_loss: 0.5513 - val_acc: 0.7163\n",
      "Epoch 20/25\n",
      "80/80 [==============================] - 13s 162ms/step - loss: 0.4914 - acc: 0.7582 - val_loss: 0.5585 - val_acc: 0.7219\n",
      "Epoch 21/25\n",
      "80/80 [==============================] - 13s 164ms/step - loss: 0.5107 - acc: 0.7477 - val_loss: 0.5150 - val_acc: 0.7734\n",
      "Epoch 22/25\n",
      "80/80 [==============================] - 13s 160ms/step - loss: 0.4876 - acc: 0.7691 - val_loss: 0.5197 - val_acc: 0.7703\n",
      "Epoch 23/25\n",
      "80/80 [==============================] - 13s 164ms/step - loss: 0.4773 - acc: 0.7750 - val_loss: 0.4843 - val_acc: 0.7756\n",
      "Epoch 24/25\n",
      "80/80 [==============================] - 13s 165ms/step - loss: 0.4806 - acc: 0.7699 - val_loss: 0.5099 - val_acc: 0.7672\n",
      "Epoch 25/25\n",
      "80/80 [==============================] - 13s 163ms/step - loss: 0.4641 - acc: 0.7809 - val_loss: 0.5509 - val_acc: 0.7406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03b2ca63c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the CNN\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "classifier.fit_generator(\n",
    "        train_set,\n",
    "        steps_per_epoch=80,\n",
    "        epochs=25,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Pickel_classifier/model.pkl', 'wb')\n",
    "pickle.dump(classifier,file)\n",
    "# pickle.dump(test_set,file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
